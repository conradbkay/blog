[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Web developer, among other things"
  },
  {
    "objectID": "setup.html",
    "href": "setup.html",
    "title": "Setup",
    "section": "",
    "text": "just for me, putting this here because README shows on github profile\n\n\n\npython3 -m venv .venv\nsource .venv/bin/activate\npython -m pip install jupyter\n\n\n\n\n\n(in ~)\nwget https://github.com/quarto-dev/quarto-cli/releases/download/v1.6.42/quarto-1.6.42-linux-amd64.tar.gz\nmkdir ~/opt\ntar -C ~/opt -xvzf quarto-1.6.42-linux-amd64.tar.gz\nln -s ~/opt/quarto-1.6.42/bin/quarto ~/.local/bin/quarto\n\n\n\n\n\n( echo ““; echo ‘export PATH=$PATH:~/.local/bin’ ; echo”” ) &gt;&gt; ~/.profile source ~/.profile"
  },
  {
    "objectID": "setup.html#linux",
    "href": "setup.html#linux",
    "title": "Setup",
    "section": "",
    "text": "python3 -m venv .venv\nsource .venv/bin/activate\npython -m pip install jupyter"
  },
  {
    "objectID": "setup.html#install-quarto",
    "href": "setup.html#install-quarto",
    "title": "Setup",
    "section": "",
    "text": "(in ~)\nwget https://github.com/quarto-dev/quarto-cli/releases/download/v1.6.42/quarto-1.6.42-linux-amd64.tar.gz\nmkdir ~/opt\ntar -C ~/opt -xvzf quarto-1.6.42-linux-amd64.tar.gz\nln -s ~/opt/quarto-1.6.42/bin/quarto ~/.local/bin/quarto"
  },
  {
    "objectID": "setup.html#hack-for-now",
    "href": "setup.html#hack-for-now",
    "title": "Setup",
    "section": "",
    "text": "( echo ““; echo ‘export PATH=$PATH:~/.local/bin’ ; echo”” ) &gt;&gt; ~/.profile source ~/.profile"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Conrad Kay",
    "section": "",
    "text": "Can a computer grade comic books?\n\n\n\n\n\n\nML\n\n\n\n\n\n\n\n\n\nApr 2, 2025\n\n\nConrad Kay\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/aicg/index.html",
    "href": "posts/aicg/index.html",
    "title": "Can a computer grade comic books?",
    "section": "",
    "text": "Starting this project I knew next to nothing about training a machine learning model. I’m a web developer, not really knowledgable in math or data science. As such I’ll try and make everything understandable with just general programming knowledge\nTo me, if you want to actually . If you’re the opposite, LLMs are very appealing since you just use some API endpoint\nAny important math will come up, naturally.\n\nBackground\nThis a comic encapsulated and graded by CGC, which was the first comic grading service and remains the most popular\n\n\n\n\n\n\n\n\n\n\n\n\n\nThere are some companies (like AGS) which use AI to grade trading cards, but as far as I can tell the only attempt for comics is prompting ChatGPT. The problem is, huge multimodal models aren’t that good at grading comics. My theory would be that they rarely face a scenario in their training data where it matters much to get the grade right. What they do well is responding in natural language,\nwell, why don’t we have AI grading comic books?\n\nThere’s no public dataset for images of physical comic books\nSeveral images are required per comic\nSome defects are very hard to detect from an image or two\nThere’s a\nComic covers have a lot of art and color\n\nThat last point is to me the most interesting. If you don’t have a reference copy available, there’s a level of “intelligence” required to . It’s the type of thing effortless/subconscious for humans, but difficult for computers and nearly impossible without deep learning.\nThe image on the right is zoomed in at and above the “R”. Even though the number of pixels the defect takes up is the same, without the surrounding context it’s much more difficult to tell whether the top half has any defects. The lower portion is still somewhat trivial, since it’s rare for something to occur naturally.\n \n\n\nApproach\nIt’s very reasonable frame this as either a object detection problem.\n\n\nMaking the dataset\nThere’s a lot of graded comic books on the internet because lots of people sell them. Most of the photos are pretty bad though. The cases are so reflective in good lighting that they’re practically mirrors, which means often taking pictures at an off angle. A lot of listings don’t even include the back cover which is equally important to the grade.\nRemember that bias and consistency score? Now that we have a model, .\n\n\nPre-processing the images\nIdeally, we don’t want to waste any pixels which means\nTraditional computer vision techniques struggled quite a bit\nI ended up writing an algorithm to scan from each edge\nThe bottom of the plastic casing has a lot of color changes before the comic which proved difficult to sort out since it’s not very consistent\nmy proposed solution 1. Get a ton of images of already graded comics from the internet 2. throw a ton of compute/ML at it 3. combine each\nMost of the grade impact is in the 10% of pixels at the edges of each comic\n\n\nEDA\n[Show a graph of grade by year (5 at a time) and also label type. Before and after filtering for ML input]\nYear is extremely correlated. Cheaper books aren’t worth grading unless a high grade is expected (often 9.8 or bust)\nWe could account for the imbalance in our loss function. Another approach is making our dataset more concentrated on outliers\n\n\nPre-trained models\nAll the models I’ve used so far had already been trained on a ton of natural images. Even though most of what they learned isn’t applicable to the task, almost anything is better than starting from scratch.\nThe DINO method https://arxiv.org/abs/2104.14294 is really interesting, and I found models trained using it to perform very well. Just training a simple classifier on top of a pre-trained models 384 output\nThe approach of not using any label is quite fascinating. As a crude analogy, compare it to giving a bunch of paintings to someone who doesn’t know much about art, and having them sort it into groups/piles.\nIf you gave several versions of painting, with random flipping/mirroring, cropping, hue changes, etc. they’ll probably do worse, but are forced to learn more robust ways to categorize paintings. Maybe you merge two paintings somehow, and expect them to place it somewhere in-between the two groups.\nIf instead of one person, it was closer to a game of telephone where nobody spoke a common language, they’d probably learn to just focus on the important parts\n\n\nBenchmark\nit’s always good to start with an exceedingly simple baseline. Guessing a year’s average on a training dataset of just CGC comics results in an MAE of 1.02\nThe next logical step is to see how well people do, and luckily there’s an entire forum of people asking for grades, often posting the official results when they come back. The only issue is that the average comic will be different, since people might only post their most expensive submissions or anything particularly “tough” to grade.\nfor 151 guesses over 34 posts the MAE was 0.80, and taking the average guess for each post results in a MAE of 0.74.\nMAE stands for mean absolute error, basically how far off a guess is on average\nYou can see how well you do on the dataset here https://www.conradkay.com/grade\nMy MAE on the dataset is around 0.55. I used the high-res scans and took 15 seconds on average which is very short.\n\n\nGrad-CAM\n\n\n\nThe front and back cover happen to be almost identical for this comic, so it looks a bit like certain columns were duplicated\n\n\nGenerating these visualizations is fairly simple, in both code and computation. We force PyTorch to do some calculus measuring how much each region contributes to the model’s output, which gets normalized and reshaped into basically a grayscale image matching our input image’s dimensions. OpenCV makes it easy to use a colormap (JET) so that instead of displaying black to white, it shows blue to yellow to red\nThese give a way to basically check the model’s work. If it misses anything that seems significant, the grade is probably lower than it predicts. The model paying attention to things which aren’t defects is more nuanced. You could imagine that for a flawless comic, the attention map\n\n\nMore Data\nSo far the model has only been trained on already CGC/CBCS graded comics\nImagine we take several different graders . We can get a bias score, and a consistency score. It doesn’t matter much how accurate the model is, as long as it’s grades average out to being correct it will have a bias of 0, and we can arbitrarily set a consistency of 1 as equaling the model.\nBasically we can create a model to convert one of their grades into the probabilities our model would output on average. So if they gave a comic an 8.5, we might output 40% 8.5, 30% 9.0, 15% 8.0, 0.4% 9.6, etc.\nEssentially, that converts their grading format– which is usually the same 0.5-10, but often less precise or biased in a specific direction–into CGC’s format. It’s fairly unlikely. The only thing to really worry about is more specific biases. Training on worse/less applicable data first is a common theme in ML, and should greatly mitigate this.\nAn easy to increase data quality is to look at the biggest losses manually and decide whether to remove, relabel, or keep for future training runs. At the very least, this makes it very apparent what the model’s limitations and weaknesses are."
  }
]