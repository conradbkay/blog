<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.42">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Conrad Kay">
<meta name="dcterms.date" content="2025-04-02">

<title>Deep Comic Book Grading – conradkay.com</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script><script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-2f5df379a58b258e96c21c0638c20c03.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap-975eae43cefc8a6005c0d5ec824cefa0.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script src="../../site_libs/quarto-diagram/mermaid.min.js"></script>
<script src="../../site_libs/quarto-diagram/mermaid-init.js"></script>
<link href="../../site_libs/quarto-diagram/mermaid.css" rel="stylesheet">
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>

<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>


<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-fixed fullcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">conradkay.com</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../about.html"> 
<span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/conradbkay"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">Deep Comic Book Grading</h1>
                                <div class="quarto-categories">
                <div class="quarto-category">ML</div>
                <div class="quarto-category">featured</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Conrad Kay </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">April 2, 2025</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">





<p><strong>Update</strong>: You can benchmark yourself against the model’s exact predictions here: <a href="https://ai.conradkay.com/grade" class="uri">https://ai.conradkay.com/grade</a></p>
<p>Attempting this project as a web developer without a math or data science background was a long shot, but I ended up getting better results than I thought was possible.</p>
<section id="background" class="level1">
<h1>Background</h1>
<p>This a comic graded and encapsulated by CGC, which was the first comic book grading service and remains the most popular.</p>
<div>

</div>
<div class="quarto-layout-panel" data-layout-ncol="3">
<div class="quarto-layout-row">
<div class="quarto-layout-cell" style="flex-basis: 33.3%;justify-content: center;">
<p><img src="assets/power2-f.jpg" class="img-fluid"></p>
</div>
<div class="quarto-layout-cell" style="flex-basis: 33.3%;justify-content: center;">
<p><img src="assets/power2-b.jpg" class="img-fluid"></p>
</div>
</div>
</div>
<p>There are some companies (AGS) which use AI to grade trading cards, but nothing has been used for comic books except asking chatbots.</p>
<p>After trying a few popular models I began to suspect they were basically spitting out the “average” grade, which gets lower as the comic’s age increases. To test that I gave them some very high-grade old comics, and a couple lower-grade modern comics.</p>
<p>Prompt: “As a professional CGC grader, use the provided scans of the front and back cover to assign a grade from 0.5 to 10.” Prompting to describe any the defects <em>before</em> assigning a grade didn’t seem to help.</p>
<div id="1a7c4321" class="cell" data-execution_count="1">
<div class="cell-output cell-output-display">
        <script type="text/javascript">
        window.PlotlyConfig = {MathJaxConfig: 'local'};
        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: "STIX-Web"}});}
        </script>
        <script type="module">import "https://cdn.plot.ly/plotly-3.0.1.min"</script>
        
</div>
<div class="cell-output cell-output-display">
<div>            <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG"></script><script type="text/javascript">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: "STIX-Web"}});}</script>                <script type="text/javascript">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>
        <script charset="utf-8" src="https://cdn.plot.ly/plotly-3.0.1.min.js"></script>                <div id="f9fbeb5d-5c98-492c-8375-612ed42b4c45" class="plotly-graph-div" style="height:300px; width:640px;"></div>            <script type="text/javascript">                window.PLOTLYENV=window.PLOTLYENV || {};                                if (document.getElementById("f9fbeb5d-5c98-492c-8375-612ed42b4c45")) {                    Plotly.newPlot(                        "f9fbeb5d-5c98-492c-8375-612ed42b4c45",                        [{"customdata":[["Claude 3.7 Sonnet",1965,"6.0",6.0,3.4000000000000004],["Claude 3.7 Sonnet",1963,"6.0",6.0,3.4000000000000004],["ChatGPT (o4-mini)",1965,"7.5",7.5,1.9000000000000004],["ChatGPT (o4-mini)",1963,"5.5-6.0",5.75,3.6500000000000004],["Gemini 2.5 Pro",1944,"5.0",5.0,4.800000000000001],["Gemini 2.5 Pro",1959,"4.5-5.5",5.0,4.4],["Gemini 2.5 Pro",2006,"9.6",9.6,-3.5999999999999996],["Gemini 2.5 Pro",1988,"7.0-7.5",7.25,-3.25]],"hovertemplate":"\u003cb\u003eModel: %{customdata[0]}\u003c\u002fb\u003e\u003cbr\u003eComic Year: %{customdata[1]}\u003cbr\u003e---\u003cbr\u003e\u003cb\u003eActual Grade: %{y:.1f}\u003c\u002fb\u003e\u003cbr\u003e","marker":{"color":["rgb(23, 190, 207)","rgb(23, 190, 207)","rgb(31, 119, 180)","rgb(31, 119, 180)","rgb(255, 127, 14)","rgb(255, 127, 14)","rgb(255, 127, 14)","rgb(255, 127, 14)"],"line":{"color":"DarkSlateGrey","width":1.5},"size":10,"symbol":"circle"},"mode":"markers","name":"Actual Grade","x":{"dtype":"i1","bdata":"AAECAwQFBgc="},"y":{"dtype":"f8","bdata":"zczMzMzMIkDNzMzMzMwiQM3MzMzMzCJAzczMzMzMIkCamZmZmZkjQM3MzMzMzCJAAAAAAAAAGEAAAAAAAAAQQA=="},"type":"scatter"},{"customdata":[["Claude 3.7 Sonnet",1965,9.4,"6.0",3.4000000000000004],["Claude 3.7 Sonnet",1963,9.4,"6.0",3.4000000000000004],["ChatGPT (o4-mini)",1965,9.4,"7.5",1.9000000000000004],["ChatGPT (o4-mini)",1963,9.4,"5.5-6.0",3.6500000000000004],["Gemini 2.5 Pro",1944,9.8,"5.0",4.800000000000001],["Gemini 2.5 Pro",1959,9.4,"4.5-5.5",4.4],["Gemini 2.5 Pro",2006,6.0,"9.6",-3.5999999999999996],["Gemini 2.5 Pro",1988,4.0,"7.0-7.5",-3.25]],"hovertemplate":"%{customdata[3]}\u003cbr\u003e","marker":{"color":["rgb(23, 190, 207)","rgb(23, 190, 207)","rgb(31, 119, 180)","rgb(31, 119, 180)","rgb(255, 127, 14)","rgb(255, 127, 14)","rgb(255, 127, 14)","rgb(255, 127, 14)"],"line":{"color":"DarkSlateGrey","width":1.5},"size":10,"symbol":"x"},"mode":"markers","name":"Guessed Grade","x":{"dtype":"i1","bdata":"AAECAwQFBgc="},"y":{"dtype":"f8","bdata":"AAAAAAAAGEAAAAAAAAAYQAAAAAAAAB5AAAAAAAAAF0AAAAAAAAAUQAAAAAAAABRAMzMzMzMzI0AAAAAAAAAdQA=="},"type":"scatter"},{"legendgroup":"models","marker":{"color":"rgb(23, 190, 207)","size":10,"symbol":"square"},"mode":"markers","name":"Claude 3.7 Sonnet","showlegend":true,"x":[null],"y":[null],"type":"scatter"},{"legendgroup":"models","marker":{"color":"rgb(31, 119, 180)","size":10,"symbol":"square"},"mode":"markers","name":"ChatGPT (o4-mini)","showlegend":true,"x":[null],"y":[null],"type":"scatter"},{"legendgroup":"models","marker":{"color":"rgb(255, 127, 14)","size":10,"symbol":"square"},"mode":"markers","name":"Gemini 2.5 Pro","showlegend":true,"x":[null],"y":[null],"type":"scatter"}],                        {"template":{"data":{"barpolar":[{"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"type":"carpet"}],"choropleth":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"choropleth"}],"contourcarpet":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"contourcarpet"}],"contour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"type":"contour"}],"heatmap":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"type":"heatmap"}],"histogram2dcontour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"type":"histogram2dcontour"}],"histogram2d":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"type":"histogram2d"}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"mesh3d":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"mesh3d"}],"parcoords":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"parcoords"}],"pie":[{"automargin":true,"type":"pie"}],"scatter3d":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatter3d"}],"scattercarpet":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattercarpet"}],"scattergeo":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergeo"}],"scattergl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergl"}],"scattermapbox":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattermapbox"}],"scattermap":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattermap"}],"scatterpolargl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolargl"}],"scatterpolar":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolar"}],"scatter":[{"fillpattern":{"fillmode":"overlay","size":10,"solidity":0.2},"type":"scatter"}],"scatterternary":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterternary"}],"surface":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"type":"surface"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}]},"layout":{"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"autotypenumbers":"strict","coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]],"sequential":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"sequentialminus":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]},"colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"geo":{"bgcolor":"white","lakecolor":"white","landcolor":"white","showlakes":true,"showland":true,"subunitcolor":"#C8D4E3"},"hoverlabel":{"align":"left"},"hovermode":"closest","mapbox":{"style":"light"},"margin":{"b":0,"l":0,"r":0,"t":30},"paper_bgcolor":"white","plot_bgcolor":"white","polar":{"angularaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""},"bgcolor":"white","radialaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""}},"scene":{"xaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"yaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"zaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"ternary":{"aaxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"baxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"bgcolor":"white","caxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""}},"title":{"x":0.05},"xaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2},"yaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2}}},"shapes":[{"line":{"color":"rgb(23, 190, 207)","width":2},"opacity":0.7,"type":"line","x0":0,"x1":0,"y0":9.4,"y1":6.0},{"line":{"color":"rgb(23, 190, 207)","width":2},"opacity":0.7,"type":"line","x0":1,"x1":1,"y0":9.4,"y1":6.0},{"line":{"color":"rgb(31, 119, 180)","width":2},"opacity":0.7,"type":"line","x0":2,"x1":2,"y0":9.4,"y1":7.5},{"line":{"color":"rgb(31, 119, 180)","width":2},"opacity":0.7,"type":"line","x0":3,"x1":3,"y0":9.4,"y1":5.75},{"line":{"color":"rgb(255, 127, 14)","width":2},"opacity":0.7,"type":"line","x0":4,"x1":4,"y0":9.8,"y1":5.0},{"line":{"color":"rgb(255, 127, 14)","width":2},"opacity":0.7,"type":"line","x0":5,"x1":5,"y0":9.4,"y1":5.0},{"line":{"color":"rgb(255, 127, 14)","width":2},"opacity":0.7,"type":"line","x0":6,"x1":6,"y0":6.0,"y1":9.6},{"line":{"color":"rgb(255, 127, 14)","width":2},"opacity":0.7,"type":"line","x0":7,"x1":7,"y0":4.0,"y1":7.25}],"legend":{"title":{"text":"Legend"}},"xaxis":{"title":{"text":"Sample Year"},"tickmode":"array","tickvals":{"dtype":"i1","bdata":"AAECAwQFBgc="},"ticktext":["1965","1963","1965","1963","1944","1959","2006","1988"],"tickangle":0},"yaxis":{"title":{"text":"Grade"},"range":[3.5,10],"dtick":1.0},"height":300,"width":640,"hovermode":"x unified"},                        {"responsive": true}                    ).then(function(){
                            
var gd = document.getElementById('f9fbeb5d-5c98-492c-8375-612ed42b4c45');
var x = new MutationObserver(function (mutations, observer) {{
        var display = window.getComputedStyle(gd).display;
        if (!display || display === 'none') {{
            console.log([gd, 'removed!']);
            Plotly.purge(gd);
            observer.disconnect();
        }}
}});

// Listen for the removal of the full notebook cells
var notebookContainer = gd.closest('#notebook-container');
if (notebookContainer) {{
    x.observe(notebookContainer, {childList: true});
}}

// Listen for the clearing of the current output cell
var outputEl = gd.closest('.output');
if (outputEl) {{
    x.observe(outputEl, {childList: true});
}}

                        })                };            </script>        </div>
</div>
</div>
<p><br> They barely did better than just random guessing, and the explanations were very well-written but ultimately BS. For many tasks they have remarkable vision capabilities (see <a href="https://www.astralcodexten.com/p/testing-ais-geoguessr-genius" class="uri">https://www.astralcodexten.com/p/testing-ais-geoguessr-genius</a>), just this one doesn’t gel with their training.</p>
<section id="gathering-data" class="level2">
<h2 class="anchored" data-anchor-id="gathering-data">Gathering Data</h2>
<p>Getting (good) data is the hardest part for most real-world ML projects. But there’s plenty of excellent datasets of all sizes available for free, and the process of obtaining data depends so much on the task that I get too in the weeds here. Essentially it was a lot of scraping sales listings.</p>
<p>For just CGC graded comics, I got ~2.1m pairs of images, or ~7TB of .jpg files which is rather annoying.</p>
<p>eBay listings have 0-12 images, each at most 1600x1600. Anyone can post on eBay so the images are very diverse and unstructured. I’m scraping the data for now, but to be usable for training they’d need additional filtering and processing.</p>
</section>
<section id="exploratory-data-analysis-eda" class="level2">
<h2 class="anchored" data-anchor-id="exploratory-data-analysis-eda">Exploratory Data Analysis (EDA)</h2>
<p>Some things to note about grading:</p>
<ul>
<li>The front and back cover are equally important, but it’s rare for the interior pages to impact the grade</li>
<li>Manufacturing defects are mostly ignored except for grades above 9.8, which are extremely rare</li>
<li>Cheaper comics aren’t worth grading unless a high grade is expected (often 9.8 or bust)</li>
<li>Older comics are much more scarce, but therefore expensive and more likely to be graded</li>
</ul>
<p>I made a bunch of visualizations and reports to understand the data better. This heatmap is probably the most succinct</p>
<p><img src="assets/year-grade.jpg" class="img-fluid"></p>
</section>
<section id="designing-a-dataset" class="level2">
<h2 class="anchored" data-anchor-id="designing-a-dataset">Designing a Dataset</h2>
<p>There’s a few unique and interesting constraints here:</p>
<ul>
<li></li>
</ul>
<!--
At first I just limited the number of comics in each grade, then I did year+grade buckets. But it still wasn't diverse enough so I made it 
-->
<p>A scoring based approach seemed natural</p>
<p>Each year grouping is treated as a separate dataset, and an initial pass just determines the size of each.</p>
<p>I made each year (range) a heap,</p>
<p>This maximizes image diversity, smooths the total distribution of grades, and limits the effectiveness of grading based on year or the specific comic</p>
<p>The validation set is created first on a random 10% of the data, so it can’t steal all the highest score examples. A better way than random splitting would be to make every data source (what site/seller) exclusive to either the training or validation set. That way it’s clear if the model doesn’t generalize to things like different camera usage, backgrounds, or scanner settings.</p>
<p>I didn’t bother creating a test set since new data comes in fast enough I could just create one on the fly.</p>
<p><img src="assets/year-grade-ds.jpg" class="img-fluid"></p>
</section>
</section>
<section id="image-pre-processing" class="level1">
<h1>Image Pre-processing</h1>
<p>224x224 is the most common resolution for computer vision models. Most of the combined front and back cover scans are rougly 4000x3000, or 239 times as many pixels.</p>
<p>I don’t have VC money to burn, so if I don’t want to be financially ruined the name of the game is to keep as much information as possible while using the least number of pixels.</p>
<p>If we give a model uncropped images of CGC comics, It’ll just cheat by looking at the big grade number, so it’s necessary to remove the label, and ideally the other sides to remove meaningless pixels. Here’s what I tried:</p>
<ul>
<li>Just removing a fixed percent from each side works well enough as a baseline if images are cropped to the case already</li>
<li>Non-ML methods using <a href="https://opencv.org/">OpenCV</a> often failed with several boundaries close together, or light being wonky passing through several layers of transparent plastic</li>
<li>A custom algorithm to generate candidate edges from all 4 directions independently. Worked well when tuned for specific cases but didn’t generalize well to outliers in perspective, lighting, rotation, etc.</li>
<li>A <a href="https://huggingface.co/docs/transformers/en/model_doc/detr">DETR</a> object detection model. Handles slabbed (CGC) and ungraded comics. Fast, but requires manually labeling some images with bounding boxes. I found running <a href="https://github.com/HumanSignal/label-studio">label-studio</a> locally the easiest out of the popular annotation tools, but I ended up building my own simple web app to do it. That was honestly less difficult since I had easier control over the input and output, and LLMs are good at trivial projects like that.</li>
</ul>
<p>Most of the grade impact is in the pixels at the edges of each cover, so the simplest approach is to only use the edges. Unfortunately there’s no easy way to remove the center of an image like cropping to remove sides.</p>
<p>Doing this for both covers, there’s 2 sets of 4 images. Images are oriented to be vertical, scaled to the same height, and mirrored so that the edges are on the left.</p>
<div class="columns" style="align-items: stretch;">
<div class="column" style="width:34%;">
<p><img src="assets/flash-uncrop.jpg" class="img-fluid" style="width:100.0%"> <!--
![](assets/flash-uncrop-2.jpg){width="100%"}
--></p>
</div><div class="column" style="width:39%;">
<p><img src="assets/flash-crop.jpg" class="img-fluid" style="width:100.0%"> <!--
![](assets/flash-crop-2.jpg){width="100%"}
--></p>
</div><div class="column" style="width:27%;">
<p><img src="assets/front-cols.jpg" class="img-fluid" style="width:100.0%"></p>
</div>
</div>
<p>Later I experimented with adding the centers, but proportionally smaller. Metrics didn’t improve as much as I would have liked, so maybe differing scales within an image is a bad idea.</p>
</section>
<section id="training" class="level1">
<h1>Training</h1>
<p>All of the models I used had already been pre-trained on millions of images. Even though most of what they learned won’t be useful, anything is better than starting from scratch.</p>
<p><a href="https://github.com/huggingface/pytorch-image-models">timm</a> is a fantastic library with implementations and weights for many different models.</p>
<p>The DINO training method (<a href="https://arxiv.org/abs/2104.14294" class="uri">https://arxiv.org/abs/2104.14294</a>) is really interesting, and blew basically all of the 20 or so architectures I tested out of the water.</p>
<p>dinov2-base (87m parameters) got 0.717 MAE keeping the model frozen and just training the final classifiers. That’s shockingly good.</p>
<!--
The approach of not using any label is quite fascinating. As a crude analogy, compare it to giving a bunch of paintings to someone who doesn't know much about art, and having them sort it into groups/piles 

If you gave several versions of painting, with random flipping/mirroring, cropping, hue changes, etc. they'll probably do worse, but are forced to learn more robust ways to categorize paintings. Maybe you merge two paintings somehow, and expect them to place it somewhere in-between the two groups

If instead of one person, it was closer to a game of telephone where nobody spoke a common language, they'd probably learn to just focus on the important parts
-->
</section>
<section id="benchmark" class="level1">
<h1>Benchmark</h1>
<p>The simplest metric I’m using is mean absolute error (MAE), basically how far off a guess is on average on the 0.5-10 scale.</p>
<p>To measure human performance, I used posts from <a href="https://boards.cgccomics.com/forum/42-hey-buddy-can-you-spare-a-grade/" class="uri">https://boards.cgccomics.com/forum/42-hey-buddy-can-you-spare-a-grade/</a> where they say the official grade once it comes back from CGC. The images tend to be very high quality with a lot of different angles. While there might be a bias towards people posting harder to grade comics, the validation set is very biased towards difficult/outlier examples. Across 34 posts there were 151 predictions, with an MAE of 0.80. Using the average guess for each post results in an 0.74 MAE.</p>
<p>On the validation set, I graded 50 examples myself using full resolution scans, and got an MAE of 0.55</p>
<p>Even dinov2_small with it’s 22 million parameters beat me</p>
<p>It didn’t really feel like there was a clear weakness. Analyzing the largest differences in the model’s prediction and the official grade, I found myself usually siding with the model, meaning there were just defects not visible from the 2 images.</p>
<p>Funny enough a lot of them were just due to egregious errors and grades.</p>
<p><img src=".png" class="img-fluid"></p>
</section>
<section id="grad-cam" class="level1">
<h1>Grad-CAM</h1>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="assets/cam.jpg" class="img-fluid figure-img"></p>
<figcaption>The front and back cover are almost identical for this comic, so it looks a bit like certain columns were duplicated</figcaption>
</figure>
</div>
<p>Generating these visualizations is fairly simple, in both code and computation:</p>
<ul>
<li>We force PyTorch to do some calculus measuring much each region impacts the probability it gives for a specific output</li>
<li>That gets normalized and reshaped into a grayscale image matching our input image’s dimensions</li>
<li>OpenCV makes it easy to use a colormap (Turbo in this case) so that instead of displaying from black to white, it shows blue to yellow to red</li>
</ul>
<p>These give a way to basically check the model’s work. If it misses anything that seems significant, the grade is probably lower than it predicts. The model paying attention to things which aren’t defects is more nuanced. For flawless comics it might focus the most on sharp corners.</p>
</section>
<section id="multi-task-learning" class="level1">
<h1>Multi-task Learning</h1>
<p>Right now the model doesn’t use any language data, but it would be nice if it could describe the defects like multimodal models do. Luckily there’s a number on each comic which can be used to visit a web page that includes information about the comic and grade, and has “grading notes” a bit less than half the time.</p>
<p>Usually there’s 1-4 defects listed, which follow a rough format:</p>
<ul>
<li>light spine stress lines to cover</li>
<li>multiple moderate crease back cover</li>
<li>spine stress lines breaks color</li>
</ul>
<p>In my sample there’s ~20k unique descriptions, with 80% of them occuring less than 5 times.</p>
<p>For now I’m ignoring positional information (like “top right of back cover”) since that would increase the size by &gt;50x, and Grad-CAM can supplement that information in the results.</p>
<p>I extracted 36 unique and common defects, and converted words measuring the impact (severity, size, frequency) to a number (0-1)</p>
<p>I did the same thing with the restoration info, while page color and year were more straightforward.</p>
<p>I wouldn’t say it’s intuitive to add this these the existing model which focuses on grading. With most physical systems (a car for example), they’re either specialized and good at just a few things, or general and decent at many things. Deep learning models are closer to monsters than machines, consuming as much data as possible, and more outputs means more data. <!-- lottery ticket hypothesis, dropout, etc --></p>
<!--
I'm pretty sure it's cheating on restoration based on the label being purple, . Must be that somehow light is diffracting, or the camera is adjusting for the different color. Scary smart, the vibe training these things is somewhere between being in Jurassic Park and talking to Hannibal Lecter.
-->
<!--
It would be interesting to train a model to grade just from the grader's notes. It wouldn't be that useful, but it would help to understand them more and probably lead to designing better targets for the model.
-->
</section>
<section id="entire-process" class="level1">
<h1>Entire Process</h1>
<!--
    %% Data Acquisition
    EBAY(Comics from eBay API)
    EBAY -!!-> QL("Manual Image Type & Quality Annotation")
    QL -!!-> TRQL(Train Predictive Model and Run)
    TRQL -!!-> DB
-->
<div class="cell" data-layout-align="default">
<div class="cell-output-display">
<div>
<p></p><figure class="figure"><p></p>
<div>
<pre class="mermaid mermaid-js">flowchart TD
    SCR[Scrape Marketplaces]
    SCR --&gt; DB[Database]

    DB --&gt; DL[Download Images]
    
    DL --&gt; ANCR[Manually Crop]
    ANCR --&gt; TRCR[Train DETR Crop Model]
    TRCR --&gt; TSFM

    DL --&gt; OCR("Certificate # from OCR Model")
    OCR --&gt; SCR2("Scrape Grader's Registry (Restoration, Defects)")
    SCR2 --&gt; DB


    DB --&gt; SORT["Canonization, Filtering, and Scoring"]
    %% Splitting
    SORT --&gt; DS["Create Validation Set (5k) then Training Sets (10k-1m)"]
    DS --&gt; EDA["EDA (Exploratory Data Analysis)"]

    DS --&gt; TSFM[Generate Transformed Images at Multiple Resolutions]
    TSFM --&gt; TR[Train Model]
    TR --&gt; VIS[
      Biggest Losses
      Bias / Skew
      Grad-CAM Visualizations
    ]
</pre>
</div>
<p></p></figure><p></p>
</div>
</div>
</div>
<!--
# Contrastive Training

So far the model to being asked to somehow figure out

The model realistically has no idea.

I think it's helpful to think about how we're training two models, 

With the current method of dataset creation, only 2% of the training set wouldn't have a pair, of 4% for triplets

![](assets/canon-count.jpg)
-->
</section>
<section id="v2.0-ideas" class="level1">
<h1>v2.0 Ideas</h1>
<!-- Distillation sounds like it should be complex, but it's basically just training a model on the output probabilities of a better model. This should be quite useful for the language data because it means no defects are skipped like they might be in the actual dataset. For the grade this should help too, since there's more information in the probability distribution than just a single number 

## More Data

So far the model has only been trained on already CGC graded comics. 

Imagine we take several different graders. We can get a bias score, and a consistency score. It doesn't matter much how accurate the model is, as long as it's grades average out to being correct it will have a bias of 0, and we can arbitrarily set a consistency of 1 as equaling the model.

Basically we can create a model to convert one of their grades into the probabilities our model would output on average. So if they gave a comic an 8.5, we might output 40% 8.5, 30% 9.0, 15% 8.0, 0.4% 9.6, etc. 

Essentially, that converts their grading format-- which is usually the same 0.5-10, but often less precise or biased in a specific direction--into CGC's format. It's fairly unlikely. The only thing to really worry about is more specific biases. Training on worse/less applicable data first is a common theme in ML, and should greatly mitigate this. 

eBay and quality score
-->
<section id="takeaways" class="level2">
<h2 class="anchored" data-anchor-id="takeaways">Takeaways</h2>
<p>For everything I eventually figured out there was much trial-and-error, looking at data, analyzing failures, and getting stuck or confused.</p>
<p>The potentially huge advantage you can have over someone much more experienced in ML is specific knowledge about some domain, or unique access to data. There’s probably not something that immediately comes to mind but maybe you know someone, or having the proverbial “hammer” will make some “nail” stick out in the future.</p>
</section>
<section id="resources-i-found-useful" class="level2">
<h2 class="anchored" data-anchor-id="resources-i-found-useful">Resources I found useful</h2>
<p>I made this blog with <a href="https://quarto.org">Quarto</a>, which was easy to set up but seems very capable</p>
<p><a href="https://github.com/wesm/pydata-book">Python for Data Analysis by Wes McKinney (the creator of pandas)</a></p>
<p><a href="https://www.youtube.com/watch?v=aircAruvnKk&amp;list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi">3blue1brown Deep Learning</a></p>
<p><a href="https://www.youtube.com/@AndrejKarpathy" class="uri">https://www.youtube.com/@AndrejKarpathy</a></p>
<p><a href="https://www.youtube.com/watch?v=8SF_h3xF3cE&amp;list=PLfYUBJiXbdtSvpQjSnJJ_PmDQB_VyT5iU">fast.ai Practical Deep Learning for Coders Course</a></p>
</section>
<section id="technical-details" class="level2">
<h2 class="anchored" data-anchor-id="technical-details">Technical Details</h2>
<p>Probably skip this part if you don’t have PyTorch or ML experience</p>
<p>I found the FastAI defaults (which haven’t changed much in 7 years) really difficult to beat. There’s quite a bit of randomness in training, so even if I could get a slight improvement it’s hard to say whether it was just luck.</p>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>